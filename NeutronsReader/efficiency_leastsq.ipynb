{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_count:  632631\n",
      "sigmaN^-1:  [0.00356125 0.00220767 0.001548   0.00177863 0.00291561 0.00651981\n",
      " 0.01937461 0.07881104]\n",
      "leastsq\n",
      "pcovN:  [[3.02657506e-07]]\n",
      "infodictN:  {'fvec': array([ 0.0838178 ,  0.02951091, -0.79576725,  0.42154274,  0.04627706,\n",
      "        0.17989424,  0.14749506, -0.05613495]), 'nfev': 11, 'fjac': array([[ 1.81770866e+03,  4.70738241e-01, -1.50942667e-01,\n",
      "        -3.56271496e-01, -2.78277696e-01, -1.39620466e-01,\n",
      "        -5.08979567e-02, -1.27401971e-02]]), 'ipvt': array([1], dtype=int32), 'qtf': array([2.38775989e-07])}\n",
      "errmsgN:  Both actual and predicted relative reductions in the sum of squares\n",
      "  are at most 0.000000 and the relative error between two consecutive iterates is at \n",
      "  most 0.000000\n",
      "successN:  3\n",
      "pcovP:  [[0.82753381]]\n",
      "infodictP:  {'fvec': array([ 1.66645046e-05, -1.56969521e-09, -8.02622488e-04,  3.94565276e-04,\n",
      "        3.45030400e-05,  4.57122794e-05,  1.22892268e-05, -1.11026922e-06]), 'nfev': 15, 'fjac': array([[ 1.09927696e+00,  5.57361162e-01, -2.54780437e-01,\n",
      "        -5.23558645e-01, -2.49497877e-01, -5.59848273e-02,\n",
      "        -6.86846676e-03, -4.22688835e-04]]), 'ipvt': array([1], dtype=int32), 'qtf': array([4.44328703e-06])}\n",
      "errmsgP:  The relative error between two consecutive iterates is at most 0.000000\n",
      "successP:  2\n",
      "predicted_N:  [7.88725361e+04 2.05191367e+05 2.08140938e+05 1.05605005e+05\n",
      " 2.94248722e+04 4.73259193e+03 4.51612803e+02 2.22877273e+01]\n",
      "predicted_P:  [1.24653301e-01 3.24324921e-01 3.29018395e-01 1.66949793e-01\n",
      " 4.65213176e-02 7.48290711e-03 7.14120152e-04 3.52458373e-05]\n",
      "measured_N:  [ 78849 205178 208655 105368  29409   4705    444     23]\n",
      "measured_P:  [1.24636637e-01 3.24324922e-01 3.29821017e-01 1.66555227e-01\n",
      " 4.64868146e-02 7.43719483e-03 7.01830925e-04 3.63561065e-05]\n",
      "residuals_variance_N:  46033.59447128115\n",
      "residuals_variance_P:  1.1479923576801811e-07\n",
      "pfitP:  [0.54717732]\n",
      "perrP:  [0.00030822]\n",
      "p_sigmaP:  [0.00030822]\n",
      "\n",
      "!apprEff:  0.5468156572930809\n",
      "!pfitN:  [0.54714267]\n",
      "!perrN:  [0.00055014]\n",
      "!p_sigmaN:  [0.00055014]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import least_squares, leastsq\n",
    "import scipy.stats as st\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "measured_n = np.array([78849, 205178, 208655, 105368, 29409, 4705, 444, 23]) #, , 2, 2.0\n",
    "# measured_n = np.array([77303.0, 201021.0, 204408.0, 103187.0, 28761.0, 4658.0, 449.0, 24.0, 2.0])\n",
    "ideal_p = np.array([0.0061, 0.0608, 0.2272, 0.3460, 0.2476, 0.0906, 0.0190, 0.0024]) #, 0.0002 Vorobiev, Dushin,...\n",
    "# ideal_p = np.array([0.00674, 0.05965, 0.22055, 0.35090, 0.25438, 0.08935, 0.01674, 0.00169 + 0.00740]) #  , Zucker & Holden\n",
    "averageNeutrons = 1.7115330073273431\n",
    "idealNeutrons = 3.13\n",
    "\n",
    "kerns = 8\n",
    "\n",
    "def gkern(kernlen=kerns, efficiency=0.55):\n",
    "    K = [[0 for i in range(kernlen)] for j in range(kernlen)] \n",
    "    for i in range(kernlen):\n",
    "        for j in range(kernlen):\n",
    "            if i <= j:\n",
    "                K[i][j] = (math.factorial(j) / (math.factorial(i) * math.factorial(j - i))) * efficiency**i * (1 - efficiency)**(j - i)\n",
    "    return np.array(K)\n",
    "\n",
    "n_count = measured_n.sum()\n",
    "measured_p = measured_n / n_count\n",
    "ideal_n = ideal_p * n_count\n",
    "\n",
    "print(\"n_count: \", n_count)\n",
    "\n",
    "apprEff = averageNeutrons / idealNeutrons\n",
    "\n",
    "sigmaN = measured_n ** 0.5\n",
    "for k in range(len(sigmaN)):\n",
    "    if k > 1:\n",
    "        sigmaN[k] *= k ** 0.5\n",
    "sigmaN = sigmaN**(-1)\n",
    "print(\"sigmaN^-1: \", sigmaN)\n",
    "\n",
    "def function_from_efficiency_N(efficiency):\n",
    "    return (n_count * gkern(kerns, efficiency[0]).dot(ideal_p) - measured_n)*(sigmaN)\n",
    "\n",
    "def function_from_efficiency_P(efficiency):\n",
    "    return (gkern(kerns, efficiency[0]).dot(ideal_p)) - measured_p\n",
    "\n",
    "def predicted_from_efficiency_N(efficiency):\n",
    "    return n_count * gkern(kerns, efficiency[0]).dot(ideal_p)\n",
    "\n",
    "def predicted_from_efficiency_P(efficiency):\n",
    "    return gkern(kerns, efficiency[0]).dot(ideal_p)\n",
    "\n",
    "\n",
    "# predicted_optimal_p = function_from_efficiency([21.6])\n",
    "# print(predicted_optimal_p)\n",
    "\n",
    "#https://stackoverflow.com/questions/14854339/in-scipy-how-and-why-does-curve-fit-calculate-the-covariance-of-the-parameter-es/14857441#14857441\n",
    "#https://stackoverflow.com/questions/42388139/how-to-compute-standard-deviation-errors-with-scipy-optimize-least-squares\n",
    "#https://stackoverflow.com/questions/14581358/getting-standard-errors-on-fitted-parameters-using-the-optimize-leastsq-method-i/21844726#21844726\n",
    "\n",
    "\n",
    "# least_squares\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.least_squares.html#r20fc1df64af7-jjmore\n",
    "# print(\"least_squares\")\n",
    "# result = least_squares(function_from_efficiency, 0.5, method='lm',jac='2-point',max_nfev=1000000)\n",
    "# print(result)\n",
    "# J = result.jac\n",
    "# cov = np.linalg.inv(J.T.dot(J))\n",
    "# print(\"cov: \", cov)\n",
    "# sigma = np.sqrt(np.diagonal(cov))\n",
    "# print(\"sigma: \", sigma)\n",
    "# print(\"\")\n",
    "# print(\"\")\n",
    "\n",
    "# optimal_eff = 0.57421387\n",
    "# predicted_optimal_p = function_from_efficiency([optimal_eff])\n",
    "# print('Predicted optimal probabilities: ' + repr(predicted_optimal_p))\n",
    "# err = mean_squared_error(measured_p, predicted_optimal_p)\n",
    "# print('MSE: ' + repr(err))\n",
    "# print('RMSE: ' + repr(err ** 0.5))\n",
    "# err_abs = mean_absolute_error(measured_p, predicted_optimal_p)\n",
    "# print('MSE_abs: ' + repr(err_abs))\n",
    "# print('Cov * MSE ' + repr((cov ** 0.5) * err))\n",
    "# print('SEm ' + repr((cov ** 0.5) / (n_count ** 0.5)))\n",
    "\n",
    "# ax = plt.subplot()\n",
    "# x_array = np.arange(0.01, 0.99, 0.01)\n",
    "# y_array = np.zeros(len(x_array))\n",
    "# for i in range(len(x_array)):\n",
    "#     y = mean_squared_error(measured_p, function_from_efficiency([x_array[i]]))\n",
    "#     y_array[i] = y\n",
    "# line, = plt.plot(x_array, y_array, lw=2)\n",
    "# plt.ylim(0, 0.2)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# leastsq\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.leastsq.html\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html\n",
    "pfitN, pcovN, infodictN, errmsgN, successN = leastsq(function_from_efficiency_N, 0.5, full_output=1, epsfcn=0.0001)\n",
    "pfitP, pcovP, infodictP, errmsgP, successP = leastsq(function_from_efficiency_P, 0.5, full_output=1, epsfcn=0.0001)\n",
    "print(\"leastsq\")\n",
    "print(\"pcovN: \", pcovN)\n",
    "print(\"infodictN: \", infodictN)\n",
    "print(\"errmsgN: \", errmsgN)\n",
    "print(\"successN: \", successN)\n",
    "\n",
    "print(\"pcovP: \", pcovP)\n",
    "print(\"infodictP: \", infodictP)\n",
    "print(\"errmsgP: \", errmsgP)\n",
    "print(\"successP: \", successP)\n",
    "\n",
    "predicted_N = predicted_from_efficiency_N(pfitN)\n",
    "predicted_P = predicted_from_efficiency_P(pfitP)\n",
    "print(\"predicted_N: \", predicted_N)\n",
    "print(\"predicted_P: \", predicted_P)\n",
    "print(\"measured_N: \", measured_n)\n",
    "print(\"measured_P: \", measured_p)\n",
    "\n",
    "sum_N = 0\n",
    "sum_P = 0\n",
    "for i in range(len(measured_n)):\n",
    "    sum_N += (predicted_N[i] - measured_n[i])**2\n",
    "    sum_P += (predicted_P[i] - measured_p[i])**2\n",
    "residuals_variance_N = sum_N/(len(predicted_N)-1)\n",
    "residuals_variance_P = sum_P/(len(predicted_P)-1)\n",
    "print(\"residuals_variance_N: \", residuals_variance_N)\n",
    "print(\"residuals_variance_P: \", residuals_variance_P)\n",
    "\n",
    "pcovN = pcovN # don't multiply to residuals sum, cov already with errors\n",
    "pcovP = pcovP * residuals_variance_P\n",
    "errorN = [] \n",
    "errorP = [] \n",
    "for i in range(len(pfitN)):\n",
    "    try:\n",
    "        errorN.append(np.absolute(pcovN[i][i])**0.5)\n",
    "        errorP.append(np.absolute(pcovP[i][i])**0.5)\n",
    "    except:\n",
    "        errorN.append( 0.00 )\n",
    "        errorP.append( 0.00 ) \n",
    "\n",
    "print(\"pfitP: \", pfitP)\n",
    "print(\"perrP: \", np.array(errorP))\n",
    "p_sigmaP = np.sqrt(np.diag(pcovP))\n",
    "print(\"p_sigmaP: \", p_sigmaP)\n",
    "print(\"\")\n",
    "print(\"!apprEff: \", apprEff)\n",
    "print(\"!pfitN: \", pfitN)\n",
    "print(\"!perrN: \", np.array(errorN))\n",
    "p_sigmaN = np.sqrt(np.diag(pcovN))\n",
    "print(\"!p_sigmaN: \", p_sigmaN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
